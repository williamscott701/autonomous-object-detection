{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done\n",
      "Model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epoch: [0]  [   0/1857]  eta: 0:20:46  lr: 0.000002  loss: 1.2144 (1.2144)  loss_classifier: 0.6646 (0.6646)  loss_box_reg: 0.0123 (0.0123)  loss_objectness: 0.4900 (0.4900)  loss_rpn_box_reg: 0.0475 (0.0475)  time: 0.6712  data: 0.1201  max mem: 2152\n"
     ]
    }
   ],
   "source": [
    "# from dent_faster_rcnn.imports import *\n",
    "from imports import *\n",
    "import pickle\n",
    "# from dent_faster_rcnn.datasets.dent import *\n",
    "from datasets.dent import *\n",
    "# from dent_faster_rcnn.cfg import *\n",
    "from cfg import *\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "with open(\"datalists/dent_images_path_list.txt\", \"rb\") as fp:\n",
    "    img_paths = pickle.load(fp)\n",
    "with open(\"datalists/dent_anno_path_list.txt\", \"rb\") as fp:\n",
    "    anno_paths = pickle.load(fp)\n",
    "\n",
    "images = img_paths\n",
    "annos = anno_paths\n",
    "\n",
    "train_img_paths = []\n",
    "with open(os.path.join(dent_path, 'train.txt')) as f:\n",
    "    train_img_paths = f.readlines()\n",
    "\n",
    "for i in range(len(train_img_paths)):\n",
    "    train_img_paths[i] = train_img_paths[i].strip('\\n')\n",
    "    train_img_paths[i] = train_img_paths[i] + '.jpg'\n",
    "    img_dir = os.path.join(dent_path , 'images')\n",
    "    train_img_paths[i] = os.path.join(img_dir, train_img_paths[i])\n",
    "\n",
    "train_anno_paths = []\n",
    "for i in range(len(train_img_paths)):\n",
    "    train_anno_paths.append(train_img_paths[i].replace('images', 'Dent_annotations',1))\n",
    "    train_anno_paths[i] = train_anno_paths[i].replace('.jpg', '.xml')\n",
    "\n",
    "train_img_paths, train_anno_paths = sorted(train_img_paths), sorted(train_anno_paths)\n",
    "\n",
    "assert len(train_img_paths) == len(train_anno_paths)\n",
    "\n",
    "new_train_img_paths, new_train_anno_paths = [], []\n",
    "\n",
    "for i in range(len(train_img_paths)):\n",
    "    if (train_img_paths[i] in images):\n",
    "        new_train_img_paths.append(train_img_paths[i])\n",
    "        new_train_anno_paths.append(train_anno_paths[i])\n",
    "\n",
    "assert len(new_train_img_paths) == len(new_train_anno_paths)\n",
    "\n",
    "dataset_train = DENT(new_train_img_paths, new_train_anno_paths, get_transform(train=True))\n",
    "dl = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"Loading done\")\n",
    "\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features,\n",
    "                                                                                               num_classes)  # replace the pre-trained head with a new one\n",
    "    return model.cuda()\n",
    "\n",
    "print(\"Model initialization\")\n",
    "model = get_model(len(dataset_train.classes))\n",
    "# torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=6e-3)\n",
    "\n",
    "try:\n",
    "    os.mkdir('saved_models/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if ckpt:\n",
    "    checkpoint = torch.load('saved_models/dent.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "print('Training started')\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_one_epoch(model, optimizer, dl, device, epoch, print_freq=200)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    save_name = 'saved_models/dent_' + str(epoch) + '.pth'\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict()}, save_name)\n",
    "    print(\"Saved model\", save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
